{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# much of this code, particularly the encoder decoder code, is taken from https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "# the rest is adapted for this project but is still pretty similar\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for start and end of string\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "# Alphabet class (works with both pinyin and English)\n",
    "class Alphabet:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.letter2index = {}\n",
    "        self.letter2count = {}\n",
    "        self.index2letter = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_letters = 2\n",
    "        \n",
    "    def add_name(self, name):\n",
    "        \"\"\"\n",
    "        Adds the characters of a name to the alphabet by iterating over them\n",
    "        and updating the appropriate counts\n",
    "        \"\"\"\n",
    "        for letter in name: # for pinyin we can keep the space as a letter and see if this thing learns syllable boundries\n",
    "            if letter not in self.letter2index:\n",
    "                self.letter2index[letter] = self.n_letters\n",
    "                self.letter2count[letter] = 1\n",
    "                self.index2letter[self.n_letters] = letter\n",
    "                self.n_letters += 1\n",
    "            else:\n",
    "                self.letter2count[letter] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input names have: 28 characters\n",
      "Output names have: 49 characters\n"
     ]
    }
   ],
   "source": [
    "data_file = os.path.join(\"..\", \"data\", \"EnglishChineseNames_uniq.txt\")\n",
    "\n",
    "def normalize(s):\n",
    "    \"\"\"\n",
    "    Right now just converts a string to lowercase but could be something more later\n",
    "    (such as removing spaces)\n",
    "    \"\"\"\n",
    "    s = re.sub(r\"([-.Â·])\", r\"\", s) # remove punctuation that seems to have seeped in (including chinese dash)\n",
    "    return s.lower()\n",
    "\n",
    "def read_alphabets():\n",
    "    \"\"\"\n",
    "    Creates two alphabets, one for English / Romanized names and the other for pinyin\n",
    "    Iterates through data file to initialize those alphabets\n",
    "    \"\"\"\n",
    "    input_alph = Alphabet(\"English\")\n",
    "    output_alph = Alphabet(\"Pinyin\")\n",
    "    pairs = []\n",
    "    \n",
    "    df = pd.read_csv(data_file)\n",
    "    for row_i, row in df.iterrows():\n",
    "        english, _, _, pinyin = row\n",
    "        english = normalize(english)\n",
    "        pinyin = normalize(pinyin)\n",
    "        input_alph.add_name(english)\n",
    "        output_alph.add_name(pinyin) # includes spaces\n",
    "        pairs.append([english, pinyin])\n",
    "     \n",
    "    print(\"Input names have: {} characters\".format(input_alph.n_letters))\n",
    "    print(\"Output names have: {} characters\".format(output_alph.n_letters))\n",
    "\n",
    "\n",
    "    return input_alph, output_alph, pairs\n",
    "        \n",
    "eng_alph, pin_alph, pairs = read_alphabets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)#, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # still need an embedding\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # assume because we have 1-d data\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output = self.embedding(x).view(1, 1, -1)\n",
    "        output = F.relu(output) # regularization thing\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0])) # output is only going to have a single thing, so this is legal i guess\n",
    "        return output, hidden\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromName(alphabet, name):\n",
    "    return [alphabet.letter2index[l] for l in name]\n",
    "\n",
    "def tensorFromName(alphabet, name):\n",
    "    indexes = indexesFromName(alphabet, name)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromName(eng_alph, pair[0])\n",
    "    target_tensor = tensorFromName(pin_alph, pair[1])\n",
    "    return (input_tensor, target_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often we use the target input as input to our decoder rather than our decoder's guess\n",
    "# while training \n",
    "teacher_forcing_ratio = 0.5 \n",
    "MAX_LENGTH = 20\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "         criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden() # just 0's\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "    \n",
    "    loss = 0 # mission accomplished ;)\n",
    "    \n",
    "    # actually run the thing that encodes\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "    \n",
    "    # now its decoder time - this part changes somewhat if you add attention\n",
    "    decoder_input = torch.tensor([[SOS_token]])\n",
    "    decoder_hidden = encoder_hidden # no need for an init function\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # target is next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di] # bc we're using teacher focing\n",
    "            \n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1) # returns a tuple of the largest value and its index as tensors\n",
    "            decoder_input = topi.squeeze().detach() # I'm not totally sure what this does\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break # we're done with this sentence - we don't have to do this above bc it goes to the end of the string automatically\n",
    "    \n",
    "    \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    # run SGD which is in the encoder/decoder_optimizer object\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item()/target_length # not sure what this is, but we can see I guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied directly for profiling...\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually do the training:\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate = 0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)] # only this many?\n",
    "    criterion = nn.NLLLoss() # this is... negative log likelihood loss\n",
    "                             # it's the same as cross-entropy loss bc of the log softmax in the last layer\n",
    "    \n",
    "    for iter_i in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter_i -1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder,\n",
    "                     encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter_i % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every # calc avg loss\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter_i / n_iters),\n",
    "                                         iter_i, iter_i / n_iters * 100, print_loss_avg))\n",
    "        # for plotting loss\n",
    "        if iter_i % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#shamelessly copied from tutorial... yikes\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as training, just no targets - just rum the thing through the network\n",
    "\n",
    "def evaluate(encoder, decoder, name, max_len=MAX_LENGTH):\n",
    "    with torch.no_grad(): # not totally sure what this does tbh - probably stops from updating gradients like we do in training because we are done with training\n",
    "        input_tensor = tensorFromName(eng_alph, name)\n",
    "        input_length = input_tensor.size(0) # just the size of the first dimension\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_len, encoder.hidden_size)\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0] # is a vector \n",
    "        \n",
    "        # decoder - would have to change if added attention\n",
    "        decoder_input = torch.tensor([[SOS_token]])\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_name = []\n",
    "        \n",
    "        for di in range(max_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            \n",
    "            # transliterate to actual words \n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_name.append(\"<EOS>\")\n",
    "                break\n",
    "            else:\n",
    "                decoded_name.append(pin_alph.index2letter[topi.item()])\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "            \n",
    "        return decoded_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomLines(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_name = evaluate(encoder, decoder, pair[0])\n",
    "        print('<', ''.join(output_name[:-1]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 35s (- 8m 10s) (5000 6%) 1.0000\n",
      "1m 9s (- 7m 30s) (10000 13%) 1.0000\n",
      "1m 44s (- 6m 57s) (15000 20%) 1.0000\n",
      "2m 17s (- 6m 18s) (20000 26%) 1.0000\n",
      "2m 49s (- 5m 39s) (25000 33%) 1.0000\n",
      "3m 21s (- 5m 2s) (30000 40%) 1.0000\n",
      "3m 54s (- 4m 27s) (35000 46%) 1.0000\n",
      "4m 24s (- 3m 51s) (40000 53%) 1.0000\n",
      "4m 55s (- 3m 17s) (45000 60%) 1.0000\n",
      "5m 26s (- 2m 43s) (50000 66%) 1.0000\n",
      "5m 57s (- 2m 9s) (55000 73%) 1.0000\n",
      "6m 29s (- 1m 37s) (60000 80%) 1.0000\n",
      "6m 59s (- 1m 4s) (65000 86%) 1.0000\n",
      "7m 32s (- 0m 32s) (70000 93%) 1.0000\n",
      "8m 3s (- 0m 0s) (75000 100%) 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122bcb320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACTlJREFUeJzt212I5XUdx/HPN58qtdZakU2lMRDBIlKkkkTEqFTKbhUi\nicIbL5IuQgkSL+siohtDeqYyyJ5MAtEKgqBs14daHzaVFNfU3YoS6ibq18X5b06j7s66s3v+8+31\ngsOc8z/HOZ+dXd9z9n9ma4wRAHp5xbIHALDxxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CG\njl7WE2/dunWsrKws6+kBNqUdO3b8aYxx8oEet7S4r6ysZPv27ct6eoBNqaqeWM/jnJYBaEjcARoS\nd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjc\nARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEH\naEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2g\nIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CG\nxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoS\nd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjc\nARoSd4CGxB2gIXEHaEjcARoSd4CGxB2gIXEHaEjcARoSd4CGDhj3qvpKVe2pqp0vcX9V1Req6tGq\n+m1VnbvxMwE4GOt55f61JJfs5/5Lk5w5Xa5OctOhzwLgUBww7mOMXyT5y34e8sEk3xgLv0qypaq2\nbdRAAA7e0RvwOU5N8uSq27unY09vwOd+gRt//EAe/ONzh+NTAxwRZ7/hNbnhA28+rM9xRN9Qraqr\nq2p7VW3fu3fvkXxqgP8rG/HK/akkp6+6fdp07AXGGDcnuTlJzjvvvPFynuxwf7cD6GAjXrnfluTD\n00/NvDPJ38YYh+WUDADrc8BX7lV1S5KLkmytqt1JbkhyTJKMMb6Y5CdJLkvyaJJ/JPnI4RoLwPoc\nMO5jjCsPcP9Ics2GLQLgkPkXqgANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO\n0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtA\nQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gAN\niTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk\n7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4\nAzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO\n0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtAQ+IO0JC4AzQk7gANiTtA\nQ+IO0JC4AzRUY4zlPHHV3iRPvMz/fGuSP23gnMPBxkM3932JjRth7vuSeW184xjj5AM9aGlxPxRV\ntX2Mcd6yd+yPjYdu7vsSGzfC3Pclm2PjWk7LADQk7gANbda437zsAetg46Gb+77Exo0w933J5tj4\nPzblOXcA9m+zvnIHYD82Xdyr6pKq2lVVj1bVdUvc8ZWq2lNVO1cde11V3VlVj0wfT1p13/XT5l1V\n9b4jsO/0qvp5VT1YVQ9U1cfntLGqXllVd1fV/dO+G+e0b83Wo6rq3qq6fY4bq+rxqvpdVd1XVdvn\ntrGqtlTVrVX1cFU9VFXnz2zfWdPXbt/luaq6dk4bX5Yxxqa5JDkqyWNJ3pTk2CT3Jzl7SVsuTHJu\nkp2rjn02yXXT9euSfGa6fva09bgkZ0y/hqMO875tSc6drp+Y5PfTjllsTFJJTpiuH5Pk10neOZd9\na7Z+Ism3k9w+t9/n6XkfT7J1zbHZbEzy9SQfm64fm2TLnPat2XpUkmeSvHGuG9f9a1n2gIP8wp+f\n5I5Vt69Pcv0S96zkf+O+K8m26fq2JLtebGeSO5Kcf4S3/ijJe+a4Mcmrk9yT5B1z25fktCQ/TXLx\nqrjPbeOLxX0WG5O8NskfMr2/N7d9L7L3vUl+OeeN671sttMypyZ5ctXt3dOxuThljPH0dP2ZJKdM\n15e6u6pWkpyTxavj2WycTnfcl2RPkjvHGLPaN/l8kk8m+feqY3PbOJLcVVU7qurqmW08I8neJF+d\nTm19qaqOn9G+ta5Icst0fa4b12WzxX3TGItv6Uv/UaSqOiHJ95JcO8Z4bvV9y944xvjXGONtWbw6\nfntVvWXN/UvdV1XvT7JnjLHjpR6z7I2TC6av46VJrqmqC1ffueSNR2dx+vKmMcY5Sf6exSmO/5rJ\n1zBVdWySy5N8d+19c9l4MDZb3J9Kcvqq26dNx+bi2araliTTxz3T8aXsrqpjsgj7t8YY35/jxiQZ\nY/w1yc+TXDKzfe9KcnlVPZ7kO0kurqpvzmxjxhhPTR/3JPlBkrfPaOPuJLunv5Ulya1ZxH4u+1a7\nNMk9Y4xnp9tz3Lhumy3uv0lyZlWdMX2XvSLJbUvetNptSa6arl+VxXnufcevqKrjquqMJGcmuftw\nDqmqSvLlJA+NMT43t41VdXJVbZmuvyqL9wMensu+JBljXD/GOG2MsZLFn7WfjTE+NKeNVXV8VZ24\n73oW54x3zmXjGOOZJE9W1VnToXcneXAu+9a4Ms+fktm3ZW4b12/ZJ/1fxhsel2Xxkx+PJfnUEnfc\nkuTpJP/M4tXJR5O8Pos33x5JcleS1616/KemzbuSXHoE9l2QxV8jf5vkvuly2Vw2JnlrknunfTuT\nfHo6Pot9L7L3ojz/hupsNmbxk2P3T5cH9v0/MbONb0uyffq9/mGSk+a0b3rO45P8OclrVx2b1caD\nvfgXqgANbbbTMgCsg7gDNCTuAA2JO0BD4g7QkLgDNCTuAA2JO0BD/wEU7zLJNfUVKAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122b3fc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now actually do the thing!\n",
    "hidden_size = 64\n",
    "encoder1 = EncoderRNN(eng_alph.n_letters, hidden_size)\n",
    "decoder1 = DecoderRNN(hidden_size, pin_alph.n_letters)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> matthew\n",
      "= mÇ xiÅ«\n",
      "< mÇ xiÄ sÄ«\n",
      "\n",
      "> maurice\n",
      "= mÃ³ lÇ sÄ«\n",
      "< mÃ¹ lÇ sÄ«\n",
      "\n",
      "> laurel\n",
      "= luÃ³ ruÃ¬ Är\n",
      "< lÃ¡o Är Är\n",
      "\n",
      "> iban\n",
      "= yÄ« bÄng\n",
      "< yÄ« bÄng\n",
      "\n",
      "> ulysses\n",
      "= yÃ³u lÇ xÄ« sÄ«\n",
      "< yiÃ¡ lÃ¬ sÄ«\n",
      "\n",
      "> jackie\n",
      "= jiÃ© kÃ¨\n",
      "< jiÃ© jÄ«\n",
      "\n",
      "> ted\n",
      "= tÃ i dÃ©\n",
      "< tÃ i dÃ©\n",
      "\n",
      "> ina\n",
      "= Ã i nÃ \n",
      "< Ã i nÃ \n",
      "\n",
      "> veronica\n",
      "= wÃ©i luÅ nÃ­ kÇ\n",
      "< wÃ©i lÄi nÃ \n",
      "\n",
      "> darian\n",
      "= dÃ¡ lÇ Än\n",
      "< dÃ¡ lÇ Än\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomLines(encoder1, decoder1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def save_model(encoder, decoder):\n",
    "    torch.save(encoder.state_dict(), os.path.join(\"..\", \"models\", \"encoder-{date:%Y-%m-%d-%H:%M:%S}\".format(date=datetime.datetime.now())))\n",
    "    torch.save(decoder.state_dict(), os.path.join(\"..\", \"models\", \"decoder-{date:%Y-%m-%d-%H:%M:%S}\".format(date=datetime.datetime.now())))\n",
    "\n",
    "save_model(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(encoder_path, decoder_path):\n",
    "    encoder1 = EncoderRNN(eng_alph.n_letters, hidden_size)\n",
    "    decoder1 = DecoderRNN(hidden_size, pin_alph.n_letters)\n",
    "    encoder1.load_state_dict(torch.load(encoder_path))\n",
    "    decoder1.load_state_dict(torch.load(decoder_path))\n",
    "    return encoder1, decoder1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'EOS',\n",
       " 'SOS',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'Ã ',\n",
       " 'Ã¡',\n",
       " 'Ã¨',\n",
       " 'Ã©',\n",
       " 'Ã¬',\n",
       " 'Ã­',\n",
       " 'Ã²',\n",
       " 'Ã³',\n",
       " 'Ã¹',\n",
       " 'Ãº',\n",
       " 'Ã¼',\n",
       " 'Ä',\n",
       " 'Ä',\n",
       " 'Ä',\n",
       " 'Ä«',\n",
       " 'Å',\n",
       " 'Å«',\n",
       " 'Ç',\n",
       " 'Ç',\n",
       " 'Ç',\n",
       " 'Ç',\n",
       " 'Ç']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pin_alph.index2letter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(data_file)\n",
    "max([len(x) for x in df['first name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'contains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-75e4847d1a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'first name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ã©'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/benjaminnewman/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'contains'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
