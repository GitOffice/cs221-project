{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# much of this code, particularly the encoder decoder code, is taken from https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "# the rest is adapted for this project but is still pretty similar\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for start and end of string\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "# Alphabet class (works with both pinyin and English)\n",
    "class Alphabet:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.letter2index = {}\n",
    "        self.letter2count = {}\n",
    "        self.index2letter = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_letters = 2\n",
    "        \n",
    "    def add_name(self, name):\n",
    "        \"\"\"\n",
    "        Adds the characters of a name to the alphabet by iterating over them\n",
    "        and updating the appropriate counts\n",
    "        \"\"\"\n",
    "        if self.name.lower() == \"pinyin\": # for pinyin we can use the syllables instead of the raw letters. \n",
    "            name = name.split(\" \")        # they'll still fall into the \"letter\" category though\n",
    "            \n",
    "        for letter in name: \n",
    "            if letter not in self.letter2index:\n",
    "                self.letter2index[letter] = self.n_letters\n",
    "                self.letter2count[letter] = 1\n",
    "                self.index2letter[self.n_letters] = letter\n",
    "                self.n_letters += 1\n",
    "            else:\n",
    "                self.letter2count[letter] += 1\n",
    "\n",
    "                    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input names have: 28 characters\n",
      "Output names have: 279 characters\n"
     ]
    }
   ],
   "source": [
    "data_file = os.path.join(\"..\", \"data\", \"EnglishChineseNames_uniq.txt\")\n",
    "\n",
    "def normalize(s):\n",
    "    \"\"\"\n",
    "    Right now just converts a string to lowercase but could be something more later\n",
    "    (such as removing spaces)\n",
    "    \"\"\"\n",
    "    s = re.sub(r\"([-.·])\", r\"\", s) # remove punctuation that seems to have seeped in (including chinese dash)\n",
    "    return s.lower()\n",
    "\n",
    "def read_alphabets():\n",
    "    \"\"\"\n",
    "    Creates two alphabets, one for English / Romanized names and the other for pinyin\n",
    "    Iterates through data file to initialize those alphabets\n",
    "    \"\"\"\n",
    "    input_alph = Alphabet(\"English\")\n",
    "    output_alph = Alphabet(\"Pinyin\")\n",
    "    pairs = []\n",
    "    \n",
    "    df = pd.read_csv(data_file)\n",
    "    for row_i, row in df.iterrows():\n",
    "        english, _, _, pinyin = row\n",
    "        english = normalize(english)\n",
    "        pinyin = normalize(pinyin)\n",
    "        input_alph.add_name(english)\n",
    "        output_alph.add_name(pinyin) # includes spaces\n",
    "        pairs.append([english, pinyin])\n",
    "     \n",
    "    print(\"Input names have: {} characters\".format(input_alph.n_letters))\n",
    "    print(\"Output names have: {} characters\".format(output_alph.n_letters))\n",
    "\n",
    "\n",
    "    return input_alph, output_alph, pairs\n",
    "        \n",
    "eng_alph, pin_alph, pairs = read_alphabets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Embedding is really just a lookup table that takes an index input and returns some k-dimensional vector\n",
    "        # input_size is size of table, hidden size is number of weights associated with each vector. We really only\n",
    "        # need this to be a one-hot vector for our purposes so we can probably don't need to explicity represent an \n",
    "        # embedding. The smaller our embedding dimension the more information we're giving up\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size) \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)#, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # still need an embedding\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # assume because we have 1-d data\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output = self.embedding(x).view(1, 1, -1)\n",
    "        output = F.relu(output) # regularization thing\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0])) # output is only going to have a single thing, so this is legal i guess\n",
    "        return output, hidden\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromName(alphabet, name):\n",
    "    if alphabet.name.lower() == \"english\":\n",
    "        return [alphabet.letter2index[l] for l in name]\n",
    "    else:\n",
    "        return [alphabet.letter2index[l] for l in name.split(\" \")]\n",
    "\n",
    "def tensorFromName(alphabet, name):\n",
    "    indexes = indexesFromName(alphabet, name)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromName(eng_alph, pair[0])\n",
    "    target_tensor = tensorFromName(pin_alph, pair[1])\n",
    "    return (input_tensor, target_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often we use the target input as input to our decoder rather than our decoder's guess\n",
    "# while training \n",
    "teacher_forcing_ratio = 0.5 \n",
    "MAX_LENGTH = 20\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "         criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden() # just 0's\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "    \n",
    "    loss = 0 # mission accomplished ;)\n",
    "    \n",
    "    # actually run the thing that encodes\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "    \n",
    "    # now its decoder time - this part changes somewhat if you add attention\n",
    "    decoder_input = torch.tensor([[SOS_token]])\n",
    "    decoder_hidden = encoder_hidden # no need for an init function\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # target is next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di] # bc we're using teacher focing\n",
    "            \n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1) # returns a tuple of the largest value and its index as tensors\n",
    "            decoder_input = topi.squeeze().detach() # I'm not totally sure what this does\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break # we're done with this sentence - we don't have to do this above bc it goes to the end of the string automatically\n",
    "    \n",
    "    \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    # run SGD which is in the encoder/decoder_optimizer object\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item()/target_length # not sure what this is, but we can see I guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied directly for profiling...\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually do the training:\n",
    "\n",
    "def trainIters(encoder, decoder, training_pairs, n_iters, print_every=1000, plot_every=100, learning_rate = 0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(training_pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss() # this is... negative log likelihood loss\n",
    "                             # it's the same as cross-entropy loss bc of the log softmax in the last layer\n",
    "    \n",
    "    for iter_i in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter_i -1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder,\n",
    "                     encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter_i % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every # calc avg loss\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter_i / n_iters),\n",
    "                                         iter_i, iter_i / n_iters * 100, print_loss_avg))\n",
    "        # for plotting loss\n",
    "        if iter_i % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#shamelessly copied from tutorial... yikes\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as training, just no targets - just rum the thing through the network\n",
    "\n",
    "# Same as training, just no targets - just rum the thing through the network\n",
    "\n",
    "def evaluate(encoder, decoder, name, max_len=MAX_LENGTH, target_name=None):\n",
    "    with torch.no_grad(): # not totally sure what this does tbh - probably stops from updating gradients like we do in training because we are done with training\n",
    "        input_tensor = tensorFromName(eng_alph, name)\n",
    "        input_length = input_tensor.size(0) # just the size of the first dimension\n",
    "        if target_name is not None:\n",
    "            target_tensor = tensorFromName(pin_alph, target_name)\n",
    "            target_length = target_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_len, encoder.hidden_size)\n",
    "        criterion = nn.NLLLoss()\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0] # is a vector \n",
    "        \n",
    "        # decoder - would have to change if added attention\n",
    "        decoder_input = torch.tensor([[SOS_token]])\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_name = []\n",
    "        loss = 0\n",
    "        if target_name is not None:\n",
    "            max_len = min(target_length, max_len)\n",
    "            \n",
    "        for di in range(max_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            if target_name is not None:\n",
    "                loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            # transliterate to actual words \n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_name.append(\"<EOS>\")\n",
    "                break\n",
    "            else:\n",
    "                decoded_name.append(pin_alph.index2letter[topi.item()])\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        \n",
    "        if target_name is not None:\n",
    "            #pass\n",
    "            print(\"Loss = \", loss)\n",
    "          \n",
    "        return decoded_name, loss\n",
    "\n",
    "\n",
    "# def evaluate(encoder, decoder, name, max_len=MAX_LENGTH):\n",
    "#     with torch.no_grad(): # not totally sure what this does tbh - probably stops from updating gradients like we do in training because we are done with training\n",
    "#         input_tensor = tensorFromName(eng_alph, name)\n",
    "#         input_length = input_tensor.size(0) # just the size of the first dimension\n",
    "#         encoder_hidden = encoder.initHidden()\n",
    "#         encoder_outputs = torch.zeros(max_len, encoder.hidden_size)\n",
    "        \n",
    "#         for ei in range(input_length):\n",
    "#             encoder_output, encoder_hidden = encoder(\n",
    "#                 input_tensor[ei], encoder_hidden)\n",
    "#             encoder_outputs[ei] += encoder_output[0, 0] # is a vector \n",
    "        \n",
    "#         # decoder - would have to change if added attention\n",
    "#         decoder_input = torch.tensor([[SOS_token]])\n",
    "#         decoder_hidden = encoder_hidden\n",
    "#         decoded_name = []\n",
    "        \n",
    "#         for di in range(max_len):\n",
    "#             decoder_output, decoder_hidden = decoder(\n",
    "#                 decoder_input, decoder_hidden)\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "            \n",
    "#             # transliterate to actual words \n",
    "#             if topi.item() == EOS_token:\n",
    "#                 decoded_name.append(\"<EOS>\")\n",
    "#                 break\n",
    "#             else:\n",
    "#                 decoded_name.append(pin_alph.index2letter[topi.item()])\n",
    "            \n",
    "#             decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "            \n",
    "#         return decoded_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomLines(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_name, loss = evaluate(encoder, decoder, pair[0], target_name=pair[1])\n",
    "        print('<', ''.join(output_name[:-1]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> boyce\n",
      "= bǎi yí sī\n",
      "Loss =  tensor(5.6523)\n",
      "< bàosīsī\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomLines(encoder2, decoder2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAllLines(encoder, decoder, eval_pairs, spaces = False):\n",
    "    distance = 0\n",
    "    diff_count = 0\n",
    "    total_loss = 0\n",
    "    for pair in eval_pairs:\n",
    "        output_name, loss = evaluate(encoder, decoder, pair[0], target_name=pair[1])\n",
    "        total_loss += loss\n",
    "        # maintain spaces\n",
    "        if spaces:\n",
    "            output_name  = ''.join(output_name[:-1])\n",
    "            target_name = pair[1]\n",
    "            print(output_name, target_name)\n",
    "        else:\n",
    "            # remove the space for edit distance calculations for consistency with baseline\n",
    "            output_name = ''.join(filter(lambda l: l != ' ', output_name[:-1])) # need to get rid of the <EOS> string at end\n",
    "            target_name = ''.join(filter(lambda l: l != ' ', pair[1]))\n",
    "        if output_name != target_name:\n",
    "            \n",
    "            diff_count += 1\n",
    "            distance += edit_distance_pinyin(target_name, output_name)\n",
    "    print(\"Out of {} names, {} were different, with an average edit distance of {} ({} for just the different pairs)\".format(len(eval_pairs), diff_count, distance/len(eval_pairs), distance/diff_count))\n",
    "    print(\"Average Loss was {}\".format(total_loss/len(eval_pairs)))\n",
    "\n",
    "#def evaluateAllLines(encoder, decoder, eval_pairs, spaces = False):\n",
    "#     distance = 0\n",
    "#     diff_count = 0\n",
    "#     for pair in eval_pairs:\n",
    "#         output_name = evaluate(encoder, decoder, pair[0])\n",
    "        \n",
    "#         # maintain spaces\n",
    "#         if spaces:\n",
    "#             output_name  = ''.join(output_name[:-1])\n",
    "#             target_name = pair[1]\n",
    "#             print(output_name, target_name)\n",
    "#         else:\n",
    "#             # remove the space for edit distance calculations for consistency with baseline\n",
    "#             output_name = ''.join(filter(lambda l: l != ' ', output_name[:-1])) # need to get rid of the <EOS> string at end\n",
    "#             target_name = ''.join(filter(lambda l: l != ' ', pair[1]))\n",
    "#         if output_name != target_name:\n",
    "            \n",
    "#             diff_count += 1\n",
    "#             distance += edit_distance_pinyin(target_name, output_name)\n",
    "#     print(\"Out of {} names, {} were different, with an average edit distance of {} ({} for just the different pairs)\".format(len(eval_pairs), diff_count, distance/len(eval_pairs), distance/diff_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(encoder, decoder):\n",
    "    english_names = [pair[0] for pair in pairs]\n",
    "    pinyin_names = [pair[1] for pair in pairs]\n",
    "    train_eng, test_eng, train_pin, test_pin = train_test_split(english_names, pinyin_names, test_size=100)\n",
    "    train_pairs = list(zip(train_eng, train_pin))\n",
    "    test_pairs = list(zip(test_eng, test_pin))\n",
    "    trainIters(encoder, decoder, train_pairs, 75000, print_every=5000)\n",
    "    \n",
    "    evaluateAllLines(encoder, decoder, test_pairs)\n",
    "    return train_pairs, test_pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-e383736890fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluateAllLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'golrokh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-119-d1516dfebc18>\u001b[0m in \u001b[0;36mevaluateAllLines\u001b[0;34m(encoder, decoder, eval_pairs, spaces)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_pairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# maintain spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-b3d86d8b00e2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, name, max_len, target_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# just the size of the first dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorFromName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_alph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mtarget_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-54a9bea28c04>\u001b[0m in \u001b[0;36mtensorFromName\u001b[0;34m(alphabet, name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtensorFromName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexesFromName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-54a9bea28c04>\u001b[0m in \u001b[0;36mindexesFromName\u001b[0;34m(alphabet, name)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mletter2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mletter2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtensorFromName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-54a9bea28c04>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mletter2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mletter2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtensorFromName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "evaluateAllLines(encoder2, decoder2, [('golrokh', '')], spaces = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 25s (- 6m 2s) (5000 6%) 3.4219\n",
      "0m 47s (- 5m 11s) (10000 13%) 3.2280\n",
      "1m 9s (- 4m 39s) (15000 20%) 2.9688\n",
      "1m 32s (- 4m 13s) (20000 26%) 2.7145\n",
      "1m 55s (- 3m 50s) (25000 33%) 2.4897\n",
      "2m 17s (- 3m 26s) (30000 40%) 2.3016\n",
      "2m 40s (- 3m 3s) (35000 46%) 2.1116\n",
      "3m 3s (- 2m 40s) (40000 53%) 1.9271\n",
      "3m 25s (- 2m 17s) (45000 60%) 1.8009\n",
      "3m 48s (- 1m 54s) (50000 66%) 1.6440\n",
      "4m 10s (- 1m 31s) (55000 73%) 1.5587\n",
      "4m 32s (- 1m 8s) (60000 80%) 1.4444\n",
      "4m 55s (- 0m 45s) (65000 86%) 1.3468\n",
      "5m 17s (- 0m 22s) (70000 93%) 1.2561\n",
      "5m 40s (- 0m 0s) (75000 100%) 1.1927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e90a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e910588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 100 names, 93 were different, with an average edit distance of 3.795 (4.080645161290323 for just the different pairs)\n"
     ]
    }
   ],
   "source": [
    "# now actually do the thing!\n",
    "hidden_size = eng_alph.n_letters\n",
    "encoder2 = EncoderRNN(eng_alph.n_letters, hidden_size)\n",
    "decoder2 = DecoderRNN(hidden_size, pin_alph.n_letters)\n",
    "\n",
    "train_set, test_set = train_and_evaluate(encoder2, decoder2)\n",
    "#trainIters(encoder2, decoder2, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss =  tensor(30.6239)\n",
      "Loss =  tensor(16.3986)\n",
      "Loss =  tensor(6.5815)\n",
      "Loss =  tensor(11.3915)\n",
      "Loss =  tensor(1.8326)\n",
      "Loss =  tensor(13.2649)\n",
      "Loss =  tensor(10.1928)\n",
      "Loss =  tensor(2.4712)\n",
      "Loss =  tensor(15.0221)\n",
      "Loss =  tensor(20.7955)\n",
      "Loss =  tensor(12.4677)\n",
      "Loss =  tensor(14.2011)\n",
      "Loss =  tensor(15.2266)\n",
      "Loss =  tensor(2.7897)\n",
      "Loss =  tensor(22.9438)\n",
      "Loss =  tensor(13.5468)\n",
      "Loss =  tensor(6.9521)\n",
      "Loss =  tensor(14.6436)\n",
      "Loss =  tensor(10.0947)\n",
      "Loss =  tensor(7.7440)\n",
      "Loss =  tensor(0.6744)\n",
      "Loss =  tensor(6.2406)\n",
      "Loss =  tensor(1.6703)\n",
      "Loss =  tensor(11.8615)\n",
      "Loss =  tensor(11.1750)\n",
      "Loss =  tensor(17.3431)\n",
      "Loss =  tensor(15.0114)\n",
      "Loss =  tensor(8.6609)\n",
      "Loss =  tensor(17.1692)\n",
      "Loss =  tensor(16.5499)\n",
      "Loss =  tensor(8.7968)\n",
      "Loss =  tensor(1.9974)\n",
      "Loss =  tensor(7.9596)\n",
      "Loss =  tensor(3.3015)\n",
      "Loss =  tensor(14.2220)\n",
      "Loss =  tensor(7.6585)\n",
      "Loss =  tensor(8.4760)\n",
      "Loss =  tensor(4.2564)\n",
      "Loss =  tensor(21.9266)\n",
      "Loss =  tensor(8.8419)\n",
      "Loss =  tensor(2.0153)\n",
      "Loss =  tensor(3.9385)\n",
      "Loss =  tensor(14.0858)\n",
      "Loss =  tensor(8.0206)\n",
      "Loss =  tensor(9.6963)\n",
      "Loss =  tensor(17.6495)\n",
      "Loss =  tensor(11.8150)\n",
      "Loss =  tensor(0.2303)\n",
      "Loss =  tensor(3.1685)\n",
      "Loss =  tensor(8.1650)\n",
      "Loss =  tensor(7.9984)\n",
      "Loss =  tensor(14.6680)\n",
      "Loss =  tensor(6.4853)\n",
      "Loss =  tensor(26.8385)\n",
      "Loss =  tensor(11.0014)\n",
      "Loss =  tensor(5.1294)\n",
      "Loss =  tensor(11.8285)\n",
      "Loss =  tensor(21.6197)\n",
      "Loss =  tensor(13.1583)\n",
      "Loss =  tensor(9.5690)\n",
      "Loss =  tensor(15.6155)\n",
      "Loss =  tensor(26.4987)\n",
      "Loss =  tensor(8.2671)\n",
      "Loss =  tensor(5.3719)\n",
      "Loss =  tensor(8.1524)\n",
      "Loss =  tensor(15.8340)\n",
      "Loss =  tensor(11.7887)\n",
      "Loss =  tensor(4.6087)\n",
      "Loss =  tensor(12.0780)\n",
      "Loss =  tensor(12.8007)\n",
      "Loss =  tensor(1.7452)\n",
      "Loss =  tensor(15.6574)\n",
      "Loss =  tensor(7.3739)\n",
      "Loss =  tensor(15.9313)\n",
      "Loss =  tensor(4.3011)\n",
      "Loss =  tensor(7.1153)\n",
      "Loss =  tensor(8.0451)\n",
      "Loss =  tensor(8.3212)\n",
      "Loss =  tensor(1.0891)\n",
      "Loss =  tensor(8.8800)\n",
      "Loss =  tensor(9.2740)\n",
      "Loss =  tensor(19.2472)\n",
      "Loss =  tensor(7.5510)\n",
      "Loss =  tensor(8.9109)\n",
      "Loss =  tensor(13.4605)\n",
      "Loss =  tensor(5.7924)\n",
      "Loss =  tensor(16.6570)\n",
      "Loss =  tensor(7.5584)\n",
      "Loss =  tensor(14.8011)\n",
      "Loss =  tensor(13.4045)\n",
      "Loss =  tensor(1.8060)\n",
      "Loss =  tensor(7.7132)\n",
      "Loss =  tensor(6.1559)\n",
      "Loss =  tensor(20.6374)\n",
      "Loss =  tensor(7.4973)\n",
      "Loss =  tensor(8.9945)\n",
      "Loss =  tensor(8.8961)\n",
      "Loss =  tensor(10.0605)\n",
      "Loss =  tensor(13.6015)\n",
      "Loss =  tensor(2.0527)\n",
      "Out of 100 names, 93 were different, with an average edit distance of 3.705 (3.9838709677419355 for just the different pairs)\n",
      "Average Loss was 10.536067008972168\n"
     ]
    }
   ],
   "source": [
    "evaluateAllLines(encoder2, decoder2, test_set, spaces = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> sampson\n",
      "= xīn pǔ sēn\n",
      "< shāmǔsēn\n",
      "\n",
      "> boyd\n",
      "= bù dé\n",
      "< bùdé\n",
      "\n",
      "> bernice\n",
      "= bǎi nī sī\n",
      "< bùlánní\n",
      "\n",
      "> denise\n",
      "= dān nī sī\n",
      "< wéinísī\n",
      "\n",
      "> martina\n",
      "= mǎ dì nà\n",
      "< mǎdìnà\n",
      "\n",
      "> maurice\n",
      "= mó lǐ sī\n",
      "< mǎlǐsī\n",
      "\n",
      "> cathy\n",
      "= kǎi xī\n",
      "< kǎixī\n",
      "\n",
      "> janice\n",
      "= zhān nī sī\n",
      "< zhēnnīsī\n",
      "\n",
      "> flora\n",
      "= fú luō lā\n",
      "< fúlālā\n",
      "\n",
      "> trina\n",
      "= cuī nà\n",
      "< tètènà\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomLines(encoder2, decoder2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def save_model(encoder, decoder):\n",
    "    torch.save(encoder.state_dict(), os.path.join(\"..\", \"models\", \"{date:%Y-%m-%d-%H:%M:%S}-encoder\".format(date=datetime.datetime.now())))\n",
    "    torch.save(decoder.state_dict(), os.path.join(\"..\", \"models\", \"{date:%Y-%m-%d-%H:%M:%S}-decoder\".format(date=datetime.datetime.now())))\n",
    "\n",
    "save_model(encoder2, decoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(encoder_path, decoder_path):\n",
    "    encoder1 = EncoderRNN(eng_alph.n_letters, hidden_size)\n",
    "    decoder1 = DecoderRNN(hidden_size, pin_alph.n_letters)\n",
    "    encoder1.load_state_dict(torch.load(encoder_path))\n",
    "    decoder1.load_state_dict(torch.load(decoder_path))\n",
    "    return encoder1, decoder1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcde'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EOS',\n",
       " 'SOS',\n",
       " 'bo',\n",
       " 'bài',\n",
       " 'bào',\n",
       " 'bái',\n",
       " 'bèi',\n",
       " 'bì',\n",
       " 'bó',\n",
       " 'bù',\n",
       " 'bā',\n",
       " 'bān',\n",
       " 'bāng',\n",
       " 'běn',\n",
       " 'bīn',\n",
       " 'bō',\n",
       " 'bǎi',\n",
       " 'bǎo',\n",
       " 'bǐ',\n",
       " 'chá',\n",
       " 'chè',\n",
       " 'cuì',\n",
       " 'cuī',\n",
       " 'cài',\n",
       " 'de',\n",
       " 'diān',\n",
       " 'duō',\n",
       " 'dà',\n",
       " 'dài',\n",
       " 'dào',\n",
       " 'dá',\n",
       " 'dèng',\n",
       " 'dé',\n",
       " 'dì',\n",
       " 'dí',\n",
       " 'dù',\n",
       " 'dùn',\n",
       " 'dān',\n",
       " 'dāng',\n",
       " 'dēng',\n",
       " 'dī',\n",
       " 'dīng',\n",
       " 'dōng',\n",
       " 'dōu',\n",
       " 'dū',\n",
       " 'dūn',\n",
       " 'fàn',\n",
       " 'fán',\n",
       " 'fèi',\n",
       " 'fù',\n",
       " 'fú',\n",
       " 'fāng',\n",
       " 'fēi',\n",
       " 'fēn',\n",
       " 'fěi',\n",
       " 'fū',\n",
       " 'fǎ',\n",
       " 'guān',\n",
       " 'guǒ',\n",
       " 'gài',\n",
       " 'gè',\n",
       " 'gé',\n",
       " 'gān',\n",
       " 'gāo',\n",
       " 'gē',\n",
       " 'gēn',\n",
       " 'gū',\n",
       " 'gǔ',\n",
       " 'huá',\n",
       " 'huò',\n",
       " 'hàn',\n",
       " 'hán',\n",
       " 'háo',\n",
       " 'hè',\n",
       " 'hé',\n",
       " 'hú',\n",
       " 'hā',\n",
       " 'hēng',\n",
       " 'hū',\n",
       " 'hǎi',\n",
       " 'hǎn',\n",
       " 'hǎo',\n",
       " 'jié',\n",
       " 'jiā',\n",
       " 'jiǎ',\n",
       " 'jiǎn',\n",
       " 'jì',\n",
       " 'jí',\n",
       " 'jī',\n",
       " 'jīn',\n",
       " 'kuí',\n",
       " 'kè',\n",
       " 'kòu',\n",
       " 'kù',\n",
       " 'kāng',\n",
       " 'kē',\n",
       " 'kě',\n",
       " 'kěn',\n",
       " 'kūn',\n",
       " 'kǎ',\n",
       " 'kǎi',\n",
       " 'kǎn',\n",
       " 'kǎo',\n",
       " 'lián',\n",
       " 'liáng',\n",
       " 'liè',\n",
       " 'luò',\n",
       " 'luó',\n",
       " 'luō',\n",
       " 'lài',\n",
       " 'lái',\n",
       " 'lán',\n",
       " 'láo',\n",
       " 'lè',\n",
       " 'léi',\n",
       " 'lì',\n",
       " 'lìlù',\n",
       " 'lín',\n",
       " 'líng',\n",
       " 'lóng',\n",
       " 'lù',\n",
       " 'lú',\n",
       " 'lún',\n",
       " 'lüè',\n",
       " 'lā',\n",
       " 'lēi',\n",
       " 'lěi',\n",
       " 'lǎng',\n",
       " 'lǐ',\n",
       " 'lǔ',\n",
       " 'lǜ',\n",
       " 'miù',\n",
       " 'mài',\n",
       " 'màn',\n",
       " 'mèng',\n",
       " 'méi',\n",
       " 'mén',\n",
       " 'méng',\n",
       " 'mì',\n",
       " 'míng',\n",
       " 'mò',\n",
       " 'mó',\n",
       " 'mù',\n",
       " 'měi',\n",
       " 'mī',\n",
       " 'mǎ',\n",
       " 'mǐ',\n",
       " 'mǐn',\n",
       " 'mǔ',\n",
       " 'niè',\n",
       " 'niǔ',\n",
       " 'nuò',\n",
       " 'nà',\n",
       " 'nài',\n",
       " 'nán',\n",
       " 'nèi',\n",
       " 'néng',\n",
       " 'ní',\n",
       " 'níng',\n",
       " 'nóng',\n",
       " 'nī',\n",
       " 'nǎi',\n",
       " 'nǔ',\n",
       " 'pà',\n",
       " 'pài',\n",
       " 'pèi',\n",
       " 'péi',\n",
       " 'pí',\n",
       " 'pò',\n",
       " 'pān',\n",
       " 'pǔ',\n",
       " 'qiàn',\n",
       " 'qiáng',\n",
       " 'qiáo',\n",
       " 'qiè',\n",
       " 'qióng',\n",
       " 'qiú',\n",
       " 'qì',\n",
       " 'qí',\n",
       " 'qín',\n",
       " 'qǐ',\n",
       " 'ruì',\n",
       " 'ruò',\n",
       " 'róu',\n",
       " 'shài',\n",
       " 'shào',\n",
       " 'shén',\n",
       " 'shì',\n",
       " 'shā',\n",
       " 'shān',\n",
       " 'shēng',\n",
       " 'shū',\n",
       " 'shǐ',\n",
       " 'suǒ',\n",
       " 'sà',\n",
       " 'sài',\n",
       " 'sè',\n",
       " 'sòng',\n",
       " 'sā',\n",
       " 'sāi',\n",
       " 'sāng',\n",
       " 'sēn',\n",
       " 'sī',\n",
       " 'sū',\n",
       " 'tiě',\n",
       " 'tuō',\n",
       " 'tài',\n",
       " 'táng',\n",
       " 'táo',\n",
       " 'tè',\n",
       " 'tí',\n",
       " 'tíng',\n",
       " 'tóng',\n",
       " 'tú',\n",
       " 'tāng',\n",
       " 'tīng',\n",
       " 'tǎ',\n",
       " 'tǎn',\n",
       " 'wàn',\n",
       " 'wàng',\n",
       " 'wá',\n",
       " 'wèi',\n",
       " 'wéi',\n",
       " 'wén',\n",
       " 'wò',\n",
       " 'wēi',\n",
       " 'wēn',\n",
       " 'wēng',\n",
       " 'wǎ',\n",
       " 'wǔ',\n",
       " 'xià',\n",
       " 'xiào',\n",
       " 'xiè',\n",
       " 'xiān',\n",
       " 'xiē',\n",
       " 'xiū',\n",
       " 'xiǎng',\n",
       " 'xuě',\n",
       " 'xí',\n",
       " 'xùn',\n",
       " 'xī',\n",
       " 'xīn',\n",
       " 'yuē',\n",
       " 'yà',\n",
       " 'yè',\n",
       " 'yé',\n",
       " 'yì',\n",
       " 'yí',\n",
       " 'yóu',\n",
       " 'yī',\n",
       " 'yīng',\n",
       " 'yōu',\n",
       " 'yǎ',\n",
       " 'yǐn',\n",
       " 'yǔ',\n",
       " 'zhuàng',\n",
       " 'zhè',\n",
       " 'zhé',\n",
       " 'zhì',\n",
       " 'zhā',\n",
       " 'zhān',\n",
       " 'zhēn',\n",
       " 'zhī',\n",
       " 'zhū',\n",
       " 'zuǒ',\n",
       " 'zé',\n",
       " 'zī',\n",
       " 'ài',\n",
       " 'ào',\n",
       " 'áng',\n",
       " 'è',\n",
       " 'é',\n",
       " 'ér',\n",
       " 'ā',\n",
       " 'āi',\n",
       " 'ān',\n",
       " 'ēn',\n",
       " 'ěr',\n",
       " 'ōu']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pin_alph.index2letter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(data_file)\n",
    "max([len(x) for x in df['first name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'contains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-75e4847d1a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'first name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'é'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/benjaminnewman/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'contains'"
     ]
    }
   ],
   "source": [
    "\"../models/decoder-2018-11-14-23:32:47\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifically for pinyin - doesn't penalize wrong tones as much\n",
    "def edit_distance_pinyin(str1, str2):\n",
    "    cache = {}\n",
    "    def recurse(str1, str2):\n",
    "        # base cases\n",
    "        if len(str1) == 0:\n",
    "            return len(str2)\n",
    "        elif len(str2) == 0:\n",
    "            return len(str1)\n",
    "        \n",
    "        if cache.get((str1, str2), -1) != -1:\n",
    "            return cache[(str1, str2)]\n",
    "        # recursive case\n",
    "        if str1[0] == str2[0]:\n",
    "            ed = recurse(str1[1:], str2[1:])\n",
    "            cache[(str1, str2)] = ed\n",
    "            return ed\n",
    "        if have_diff_tones(str1[0], str2[0]):\n",
    "            ed = 0.5 + recurse(str1[1:], str2[1:])\n",
    "            cache[(str1, str2)] = ed\n",
    "            return ed\n",
    "        else:\n",
    "            # min of insert into 1, insert into 2, replace\n",
    "            ed = 1 + min(recurse(str1, str2[1:]), recurse(str1[1:], str2), recurse(str1[1:], str2[1:]))\n",
    "            cache[(str1, str2)] = ed\n",
    "            return ed\n",
    "\n",
    "    return recurse(str1, str2) #- common_chars(str1, str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifically for pinyin \n",
    "def have_diff_tones(v1, v2):\n",
    "    result = False\n",
    "    if v1 in 'āáǎàa' and v2 in 'āáǎàa':\n",
    "        return True\n",
    "    elif v1 in 'ēéěèe' and v2 in 'ēéěèe':\n",
    "        return True\n",
    "    elif v1 in 'īíǐìi' and v2 in 'īíǐìi':\n",
    "        return True\n",
    "    elif v1 in 'ōóǒòo' and v2 in 'ōóǒòo':\n",
    "        return True\n",
    "    elif v1 in 'ūúǔùu' and v2 in 'ūúǔùu':\n",
    "        return True\n",
    "    elif v1 in 'ǖǘǚǜü' and v2 in 'ǖǘǚǜü':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance_pinyin('ben', 'běn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
