{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for start and end of string\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "# language class\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part copied straight from tutorial\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s) # add a space before punctuation\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s) # replace everything thats not a letter, ., ?, or ! with space\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    \n",
    "    lines = open(\"lang_data/fra-eng/fra.txt\").read().strip().split(\"\\n\")\n",
    "    \n",
    "    # each line is a tab-separated value\n",
    "    pairs = [[normalizeString(lang) for lang in line.split(\"\\t\")] for line in lines]\n",
    "    \n",
    "    # if want to translate in other way:\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BS filtering to make stuff run faster - also copied straight from website\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 160872 sentence pairs\n",
      "Trimmed to 12244 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4785\n",
      "eng 3116\n",
      "['c est une fille honnete .', 'she s an honest girl .']\n"
     ]
    }
   ],
   "source": [
    "# also copied...\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing done :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)#, device=device)\n",
    "# class EncoderRNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size):\n",
    "#         super(EncoderRNN, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "        \n",
    "#         self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "#         self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "#     def forward(self, x, hidden):\n",
    "#         print(x)\n",
    "#         embedded = self.embedding(x).view(1, 1 -1)\n",
    "#         output = embedded\n",
    "#         output, hidden = self.gru(output, hidden)\n",
    "#         return output, hidden\n",
    "    \n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # still need an embedding\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # assume because we have 1-d data\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output = self.embedding(x).view(1, 1, -1)\n",
    "        output = F.relu(output) # regularization thing\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0])) # output is only going to have a single thing, so this is legal i guess\n",
    "        return output, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sent):\n",
    "    return [lang.word2index[w] for w in sent.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sent):\n",
    "    indexes = indexesFromSentence(lang, sent)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often we use the target input as input to our decoder rather than our decoder's guess\n",
    "# while training \n",
    "teacher_forcing_ratio = 0.5 \n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "         criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden() # just 0's\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "    \n",
    "    loss = 0 # mission accomplished ;)\n",
    "    \n",
    "    # actually run the thing that encodes\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "    \n",
    "    # now its decoder time - this part changes somewhat if you add attention\n",
    "    decoder_input = torch.tensor([[SOS_token]])\n",
    "    decoder_hidden = encoder_hidden # no need for an init function\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # target is next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di] # bc we're using teacher focing\n",
    "            \n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1) # returns a tuple of the largest value and its index as tensors\n",
    "            decoder_input = topi.squeeze().detach() # I'm not totally sure what this does\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break # we're done with this sentence - we don't have to do this above bc it goes to the end of the string automatically\n",
    "    \n",
    "    \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    # SGD or something\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item()/target_length # not sure what this is, but we can see I guess\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied directly for profiling...\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually do the training:\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate = 0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)] # only this many?\n",
    "    criterion = nn.NLLLoss() # this is... negative log likelihood loss\n",
    "                             # it's the same as cross-entropy loss bc of the log softmax in the last layer\n",
    "    \n",
    "    for iter_i in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter_i -1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder,\n",
    "                     encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += 1\n",
    "        plot_loss_total += 1\n",
    "        \n",
    "        if iter_i % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every # calc avg loss\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter_i / n_iters),\n",
    "                                         iter_i, iter_i / n_iters * 100, print_loss_avg))\n",
    "        # for plotting loss\n",
    "        if iter_i % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#shamelessly copied from tutorial... yikes\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as training, just no targets - just rum the thing through the network\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_len=MAX_LENGTH):\n",
    "    with torch.no_grad(): # not totally sure what this does tbh - probably stops from updating gradients like we do in training because we are done with training\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size(0) # just the size of the first dimension\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_len, encoder.hidden_size)\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0] # is a vector \n",
    "        \n",
    "        # decoder - would have to change if added attention\n",
    "        decoder_input = torch.tensor([[SOS_token]])\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "        \n",
    "        for di in range(max_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            \n",
    "            # translate to actual words \n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append(\"<EOS>\")\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "            \n",
    "        return decoded_words\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomLines(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        print('<', ' '.join(output_words))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 57s (- 41m 20s) (5000 6%) 1.0000\n",
      "5m 55s (- 38m 31s) (10000 13%) 1.0000\n",
      "8m 54s (- 35m 37s) (15000 20%) 1.0000\n",
      "11m 56s (- 32m 49s) (20000 26%) 1.0000\n",
      "19m 28s (- 38m 57s) (25000 33%) 1.0000\n",
      "22m 28s (- 33m 42s) (30000 40%) 1.0000\n",
      "25m 29s (- 29m 8s) (35000 46%) 1.0000\n",
      "28m 30s (- 24m 56s) (40000 53%) 1.0000\n",
      "50m 18s (- 33m 32s) (45000 60%) 1.0000\n",
      "53m 18s (- 26m 39s) (50000 66%) 1.0000\n",
      "56m 20s (- 20m 29s) (55000 73%) 1.0000\n",
      "59m 20s (- 14m 50s) (60000 80%) 1.0000\n",
      "71m 27s (- 10m 59s) (65000 86%) 1.0000\n",
      "74m 28s (- 5m 19s) (70000 93%) 1.0000\n",
      "77m 30s (- 0m 0s) (75000 100%) 1.0000\n"
     ]
    }
   ],
   "source": [
    "# now actually do the thing!\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> nous sommes pas en train de regarder .\n",
      "= we re not looking .\n",
      "< we re not looking . <EOS>\n",
      "\n",
      "> ils se trouvent juste derriere moi .\n",
      "= they re right behind me .\n",
      "< they re right behind me . <EOS>\n",
      "\n",
      "> il a la cinquantaine bien tassee .\n",
      "= he s in his late fifties .\n",
      "< he s in at his fifties . <EOS>\n",
      "\n",
      "> je prends soin de moi .\n",
      "= i m looking after myself .\n",
      "< i m looking a myself of . <EOS>\n",
      "\n",
      "> tu as fini de travailler non ?\n",
      "= you re done working aren t you ?\n",
      "< you re done working aren t you ? <EOS>\n",
      "\n",
      "> il est en pyjama .\n",
      "= he is in pajamas .\n",
      "< he s in . . <EOS>\n",
      "\n",
      "> tu es tres occupee .\n",
      "= you re very busy .\n",
      "< you re very busy . <EOS>\n",
      "\n",
      "> elle est hors de danger .\n",
      "= she is out of danger .\n",
      "< she is out danger . <EOS>\n",
      "\n",
      "> je me fais des soucis pour sa securite .\n",
      "= i am concerned for her safety .\n",
      "< i am concerned for her safety . <EOS>\n",
      "\n",
      "> je ne souffre pas de lubies .\n",
      "= i m not delusional .\n",
      "< i m not sure . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomLines(encoder1, decoder1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'plot_losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-34501df54007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshowPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainIters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'plot_losses'"
     ]
    }
   ],
   "source": [
    "showPlot(trainIters.plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(a).view(-1 , 1).topk(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4]), tensor([3]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(a).topk(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(a).size()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[-0.8183,  0.6509, -0.7775, -1.4160,  0.7811,  0.8288, -0.1686,  0.5646,\n",
    "          1.4202, -0.1010, -1.8720, -1.4071,  0.3098, -0.8393, -0.2920,  0.2280,\n",
    "          0.2360, -0.8734,  0.8589,  0.0237, -0.0105,  0.1652, -1.1221,  0.9603,\n",
    "          0.1970, -0.2509, -0.5855,  0.5183,  0.6946,  0.0736,  0.9767,  0.5792,\n",
    "         -0.0312, -1.4024,  0.3942,  0.5707,  0.4053,  0.5660, -1.8723,  1.6933,\n",
    "          1.0951,  1.4414,  0.3009,  0.1762, -0.7756, -0.5205, -0.8247, -0.4371,\n",
    "          0.9644,  0.5760,  1.5931, -0.9677,  0.6735,  0.5148, -0.5505, -0.6410,\n",
    "          0.0239, -0.0303, -0.6336, -0.2867, -0.8388,  0.9322, -0.5291,  0.1694,\n",
    "          0.0947,  0.9172, -0.1857, -0.1289,  0.2437,  1.3823, -0.0694,  0.4305,\n",
    "          0.5292,  0.8521, -0.9946,  0.6015,  0.3973, -0.3843, -0.9620, -0.3600,\n",
    "          1.4966,  0.7945, -0.9318,  1.2036, -1.3363,  0.9426, -0.4320, -0.1362,\n",
    "          0.3154, -1.9034,  1.4595, -0.7882, -1.8531, -1.0643,  2.1001, -1.8699,\n",
    "          0.2824,  1.7580,  0.9011,  0.8399,  1.1082,  0.1434,  0.2387,  0.4536,\n",
    "         -0.7322, -1.4969,  0.2760, -0.4184,  0.3214,  0.3108,  0.6868,  0.2431,\n",
    "          0.7639,  1.5494,  0.5707,  0.2255, -0.5867, -1.0935,  0.8158,  0.2679,\n",
    "          1.4457,  0.5782,  0.3450, -0.6154, -0.5931, -1.8968, -0.0847, -0.6118,\n",
    "          1.5199,  0.7472,  0.0590, -0.5100, -0.1591,  0.6751, -0.7925, -1.2338,\n",
    "         -0.6377, -1.0088, -1.3172,  1.0568, -1.0751,  0.4422, -1.3927,  0.9583,\n",
    "          0.6041,  0.3221, -0.9782,  0.6495,  0.9313,  0.8721,  0.3172,  0.5276,\n",
    "          0.2107,  0.3229,  0.0928,  0.3852, -0.2961,  0.8587, -0.4703,  1.1611,\n",
    "          1.3347,  0.7322,  0.0376,  0.3937,  0.1368,  1.5847,  0.2463,  0.4411,\n",
    "         -0.2400,  0.7326, -0.5570, -0.6583, -0.4954, -0.1063,  0.5333,  1.4538,\n",
    "         -0.3872, -0.2830, -0.1765,  1.3330,  1.1949,  1.1706,  0.1179, -0.3406,\n",
    "         -0.2441,  0.6684,  1.5012,  0.7600, -0.5098, -0.1431, -0.5578,  0.0684,\n",
    "         -0.4613, -0.9837, -0.9606,  1.5722, -1.7310,  0.5229, -0.2257, -0.4074,\n",
    "          0.0748,  2.1557,  1.9826,  0.0707,  0.0983,  0.3841, -0.0819,  0.5578,\n",
    "         -2.1486,  0.5874, -0.0385,  0.3261, -1.2199, -0.7162,  1.0639, -0.9613,\n",
    "         -1.0904, -0.3295, -1.4279, -0.7445,  0.6628,  1.3855,  1.5763,  0.9051,\n",
    "          0.5788, -0.7529, -1.4163,  0.7441,  1.1355,  0.2101,  0.4652, -0.5745,\n",
    "         -0.0343,  2.5943, -0.0520, -0.6894,  0.3463, -0.3206, -0.6341,  2.1523,\n",
    "         -1.8168,  0.6194,  0.6981, -0.5470, -1.4172,  1.5467,  1.3849,  0.8182,\n",
    "         -0.5301,  0.5223,  1.2540, -0.4110, -1.1922, -0.7801,  0.9858, -0.4021]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8183,  0.6509, -0.7775, -1.4160,  0.7811,  0.8288, -0.1686,\n",
       "           0.5646,  1.4202, -0.1010, -1.8720, -1.4071,  0.3098, -0.8393,\n",
       "          -0.2920,  0.2280,  0.2360, -0.8734,  0.8589,  0.0237, -0.0105,\n",
       "           0.1652, -1.1221,  0.9603,  0.1970, -0.2509, -0.5855,  0.5183,\n",
       "           0.6946,  0.0736,  0.9767,  0.5792, -0.0312, -1.4024,  0.3942,\n",
       "           0.5707,  0.4053,  0.5660, -1.8723,  1.6933,  1.0951,  1.4414,\n",
       "           0.3009,  0.1762, -0.7756, -0.5205, -0.8247, -0.4371,  0.9644,\n",
       "           0.5760,  1.5931, -0.9677,  0.6735,  0.5148, -0.5505, -0.6410,\n",
       "           0.0239, -0.0303, -0.6336, -0.2867, -0.8388,  0.9322, -0.5291,\n",
       "           0.1694,  0.0947,  0.9172, -0.1857, -0.1289,  0.2437,  1.3823,\n",
       "          -0.0694,  0.4305,  0.5292,  0.8521, -0.9946,  0.6015,  0.3973,\n",
       "          -0.3843, -0.9620, -0.3600,  1.4966,  0.7945, -0.9318,  1.2036,\n",
       "          -1.3363,  0.9426, -0.4320, -0.1362,  0.3154, -1.9034,  1.4595,\n",
       "          -0.7882, -1.8531, -1.0643,  2.1001, -1.8699,  0.2824,  1.7580,\n",
       "           0.9011,  0.8399,  1.1082,  0.1434,  0.2387,  0.4536, -0.7322,\n",
       "          -1.4969,  0.2760, -0.4184,  0.3214,  0.3108,  0.6868,  0.2431,\n",
       "           0.7639,  1.5494,  0.5707,  0.2255, -0.5867, -1.0935,  0.8158,\n",
       "           0.2679,  1.4457,  0.5782,  0.3450, -0.6154, -0.5931, -1.8968,\n",
       "          -0.0847, -0.6118,  1.5199,  0.7472,  0.0590, -0.5100, -0.1591,\n",
       "           0.6751, -0.7925, -1.2338, -0.6377, -1.0088, -1.3172,  1.0568,\n",
       "          -1.0751,  0.4422, -1.3927,  0.9583,  0.6041,  0.3221, -0.9782,\n",
       "           0.6495,  0.9313,  0.8721,  0.3172,  0.5276,  0.2107,  0.3229,\n",
       "           0.0928,  0.3852, -0.2961,  0.8587, -0.4703,  1.1611,  1.3347,\n",
       "           0.7322,  0.0376,  0.3937,  0.1368,  1.5847,  0.2463,  0.4411,\n",
       "          -0.2400,  0.7326, -0.5570, -0.6583, -0.4954, -0.1063,  0.5333,\n",
       "           1.4538, -0.3872, -0.2830, -0.1765,  1.3330,  1.1949,  1.1706,\n",
       "           0.1179, -0.3406, -0.2441,  0.6684,  1.5012,  0.7600, -0.5098,\n",
       "          -0.1431, -0.5578,  0.0684, -0.4613, -0.9837, -0.9606,  1.5722,\n",
       "          -1.7310,  0.5229, -0.2257, -0.4074,  0.0748,  2.1557,  1.9826,\n",
       "           0.0707,  0.0983,  0.3841, -0.0819,  0.5578, -2.1486,  0.5874,\n",
       "          -0.0385,  0.3261, -1.2199, -0.7162,  1.0639, -0.9613, -1.0904,\n",
       "          -0.3295, -1.4279, -0.7445,  0.6628,  1.3855,  1.5763,  0.9051,\n",
       "           0.5788, -0.7529, -1.4163,  0.7441,  1.1355,  0.2101,  0.4652,\n",
       "          -0.5745, -0.0343,  2.5943, -0.0520, -0.6894,  0.3463, -0.3206,\n",
       "          -0.6341,  2.1523, -1.8168,  0.6194,  0.6981, -0.5470, -1.4172,\n",
       "           1.5467,  1.3849,  0.8182, -0.5301,  0.5223,  1.2540, -0.4110,\n",
       "          -1.1922, -0.7801,  0.9858, -0.4021]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
